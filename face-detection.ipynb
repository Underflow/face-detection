{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import dataset\n",
    "import fullyconn\n",
    "from fullyconn import FullyConnLayer, InputLayer\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = dataset.load_dataset()\n",
    "train_data = data[:-len(data)/2]\n",
    "train_data = np.reshape(train_data, (len(train_data), 3 * 40 * 40))\n",
    "test_data = data[len(data)/2:]\n",
    "test_data = np.reshape(test_data, (len(test_data), 3 * 40 * 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Model plan (fcc autoencoder 1600-30-1600 with MSE loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_nn():\n",
    "    print(\"Building NN\")\n",
    "    rng = np.random.RandomState(42)\n",
    "    nn = fullyconn.MLP()\n",
    "    \n",
    "    nn.add_layer(InputLayer(name=\"input\",\n",
    "                            dimension=40 * 40 * 3))\n",
    "    \n",
    "    nn.add_layer(FullyConnLayer(name=\"bottleneck-1\",\n",
    "                                dimension=150))\n",
    "    nn.add_layer(FullyConnLayer(name=\"bottleneck-2\",\n",
    "                                dimension=100))\n",
    "    nn.add_layer(FullyConnLayer(name=\"face-embedding\",\n",
    "                                dimension=50))\n",
    "    nn.add_layer(FullyConnLayer(name=\"reconstruction-1\",\n",
    "                                dimension=100))\n",
    "    nn.add_layer(FullyConnLayer(name=\"reconstruction2\",\n",
    "                                dimension=150))\n",
    "    nn.add_layer(FullyConnLayer(name=\"output\",\n",
    "                                dimension=40 * 40 * 3))\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation function (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(dataset, encode_decode):\n",
    "    # L1 distance between original example and encoded-decoded example\n",
    "    precision = np.absolute(dataset - encode_decode(dataset)).mean()\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Image\n",
    "def show_reconstruction(example, encode_decode):\n",
    "    reconstructed = encode_decode(np.array([example]))\n",
    "    \n",
    "    example = np.array(example.reshape(40, 40, 3), dtype=\"float\")\n",
    "    reconstructed = np.array(reconstructed.reshape(40, 40, 3), dtype=\"float\")\n",
    "    \n",
    "    figure()\n",
    "    subplot(121)\n",
    "    imshow(example, interpolation=\"nearest\")\n",
    "    subplot(122)\n",
    "    imshow(reconstructed, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "av = train_data[0]\n",
    "for i in range(1, 100):\n",
    "    av += train_data[i]\n",
    "av /= 100\n",
    "show_reconstruction(av, lambda x:x)\n",
    "\n",
    "samples = 500000\n",
    "filter = np.zeros((40, 40, 3), dtype=\"float32\")\n",
    "mean = [20, 20]\n",
    "cov = [[0,45],[95, 0]]\n",
    "for sample in np.round(np.random.multivariate_normal(mean,cov,samples)):\n",
    "    if sample[0] < 40 and sample[1] < 40:\n",
    "        for i in range(3):\n",
    "            filter[sample[0]][sample[1]][i] += 0.002\n",
    "            filter[sample[0]][sample[1]][i] = min(1.0, filter[sample[0]][sample[1]][i])\n",
    "filter = filter.reshape(40*40*3)\n",
    "show_reconstruction(filter, lambda x:x)\n",
    "show_reconstruction(np.multiply(filter, av), lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(nn, learning_rate, regularization, batch_size, steps):\n",
    "    test_epoch = []\n",
    "    train_epoch = []\n",
    "    train = nn.build_train(learning_rate, regularization, filter)\n",
    "    eval  = nn.build_eval()\n",
    "    for step_id in range(steps):\n",
    "        if step_id % 1 == 0:\n",
    "            display.clear_output(wait=True)\n",
    "            test_precision = precision(test_data, eval)\n",
    "            train_precision = precision(train_data, eval)\n",
    "            \n",
    "            train_epoch.append(train_precision * 100)\n",
    "            test_epoch.append(test_precision * 100)\n",
    "            \n",
    "            x = linspace(0, step_id, len(train_epoch))\n",
    "            \n",
    "            plot(x, test_epoch, 'r')\n",
    "            plot(x, train_epoch, 'b')\n",
    "            for i in range(10, 20):\n",
    "                show_reconstruction(test_data[i], eval)\n",
    "            show()\n",
    "            \n",
    "\n",
    "        for batch_id in range(0, len(train_data) / batch_size):\n",
    "            ts = train_data[batch_id * batch_size: (batch_id + 1) * batch_size] \n",
    "\n",
    "            train(ts, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn = build_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_network(nn, 0.0001, 0.00, 30, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('first_embedding.dat', 'wb') as f:\n",
    "    pickle.dump(nn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "encode = theano.function(inputs  = [nn.input],\n",
    "                         outputs = nn.layers[2].output)\n",
    "encoded_test_data = np.array(encode(test_data))\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(encoded_test_data)\n",
    "from scipy import misc\n",
    "for j in range(10):\n",
    "    query = test_data[j]\n",
    "    encoded_query = encode([query.reshape(40*40*3)])\n",
    "    _, neighbor = nbrs.kneighbors(encoded_query)\n",
    "    i = 1\n",
    "    figure()\n",
    "    subplot(1, 5, 1)\n",
    "    imshow(np.reshape(query, (40, 40, 3)))\n",
    "    for n in neighbor[0][1:]:\n",
    "        i = i + 1\n",
    "        subplot(1, 5, i)\n",
    "        imshow(np.reshape(test_data[n], (40, 40, 3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
